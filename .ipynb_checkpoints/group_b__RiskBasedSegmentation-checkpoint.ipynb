{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project - Risk Based Segmentation \n",
    "\n",
    "This is document contains a description of the task and also a starter code. \n",
    "Implement your exercise by changing only this Jupyter Notebook and the class inside RiskDataFrame.py, deliver both files. \n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Customer segmentation involves categorizing the portfolio by industry, location, revenue, account size, and number of employees and many other variables to reveal where risk and opportunity live within the portfolio. Those patterns can then provide key measurable data points for more predictive credit risk management. Taking a portfolio approach to risk management gives credit professionals a better fix on the accounts, in order to develop strategies for better serving segments that present the best opportunities. Not only that, you can work to maximize performance\n",
    "in all customer segments, even seemingly risky segments.\n",
    "\n",
    "Customer segmentation analysis can lead to several tangible improvements in credit risk management: stronger credit policies, and improved internal communication and cooperation across teams.\n",
    "\n",
    "## Task scope\n",
    "Your group is working in the retail risk modeling team and you are asked to build a class to perform risk-based segmentation and test it for car loansâ€™ customers based on given historical data of customer behavior. The class must perform the segmentation from a risk management perspective.\n",
    "\n",
    "## Class\n",
    "We will use Nico's great initial code, which extends Pandas DataFrame in a magical way turning our own class into like-Pandas:\n",
    "\n",
    "    #Initializing the inherited pd.DataFrame\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "    \n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        def func_(*args,**kwargs):\n",
    "            df = RiskDataframe(*args,**kwargs)\n",
    "            return df\n",
    "        return func_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORM YOUR OWN DATA CLEANNING & DATA PREPARATION HERE\n",
    "\n",
    "Your objective in this part is simply to prepare the data to apply to the missing_not_at_random and find_segment_split\n",
    "methods. Do not overcomplicate the data cleanning and data preparation. Keep it simple!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Example of use\\nimport pandas as pd\\nimport RiskDataframe as rdf\\nfrom datetime import datetime\\nfrom datetime import timedelta\\n\\n\\ndataframe = pd.read_csv(\"AUTO_LOANS_DATA.csv\", sep=\";\")\\ndataframe[\\'BINARIZED_TARGET\\'] = dataframe[\\'BUCKET\\'].apply(lambda x: 1 if x>0 else 0)\\n\\n# PERFORM YOUR OWN DATA CLEANNING & DATA PREPARATION HERE - START!\\n# Use any data cleanning / data preparation from individual project / it won\\'t be assessed here)!\\ndataframe = dataframe[dataframe[\\'PROGRAM_NAME\\'].str.contains(\"Corporate\")==False]    \\ndataframe.sort_values(by=[\\'LOAN_OPEN_DATE\\'])\\ndataframe.drop_duplicates(\\'CUSTOMER_ID\\', keep = \\'last\\', inplace = True)\\ndataframe.drop(\\'ACCOUNT_NUMBER\\', inplace=True, axis=1)\\ndataframe.drop(\\'CUSTOMER_ID\\', inplace=True, axis=1)\\ndataframe.drop(\\'BUCKET\\', inplace=True, axis=1)\\n# PERFORM YOUR OWN DATA CLEANNING HERE  - END!\\n\\nmyrdf = rdf.RiskDataframe(dataframe)\\nmyrdf.shape'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Example of use\n",
    "import pandas as pd\n",
    "import RiskDataframe as rdf\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv(\"AUTO_LOANS_DATA.csv\", sep=\";\")\n",
    "dataframe['BINARIZED_TARGET'] = dataframe['BUCKET'].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "# PERFORM YOUR OWN DATA CLEANNING & DATA PREPARATION HERE - START!\n",
    "# Use any data cleanning / data preparation from individual project / it won't be assessed here)!\n",
    "dataframe = dataframe[dataframe['PROGRAM_NAME'].str.contains(\"Corporate\")==False]    \n",
    "dataframe.sort_values(by=['LOAN_OPEN_DATE'])\n",
    "dataframe.drop_duplicates('CUSTOMER_ID', keep = 'last', inplace = True)\n",
    "dataframe.drop('ACCOUNT_NUMBER', inplace=True, axis=1)\n",
    "dataframe.drop('CUSTOMER_ID', inplace=True, axis=1)\n",
    "dataframe.drop('BUCKET', inplace=True, axis=1)\n",
    "# PERFORM YOUR OWN DATA CLEANNING HERE  - END!\n",
    "\n",
    "myrdf = rdf.RiskDataframe(dataframe)\n",
    "myrdf.shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sebastians data cleaning/prep\n",
    "import RiskDataframe as rdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_excel('AUTO_LOANS_DATA.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing account number and costumer id as no value in them\n",
    "df = df.drop(['ACCOUNT_NUMBER', 'CUSTOMER_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrdf = rdf.RiskDataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REPORTING_DATE', 'PROGRAM_NAME', 'LOAN_OPEN_DATE',\n",
       "       'EXPECTED_CLOSE_DATE', 'ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING',\n",
       "       'BUCKET', 'SEX', 'CUSTOMER_OPEN_DATE', 'BIRTH_DATE', 'PROFESSION',\n",
       "       'CAR_TYPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING', 'BUCKET'],\n",
       " ['PROGRAM_NAME', 'SEX', 'PROFESSION', 'CAR_TYPE'],\n",
       " ['REPORTING_DATE',\n",
       "  'LOAN_OPEN_DATE',\n",
       "  'EXPECTED_CLOSE_DATE',\n",
       "  'CUSTOMER_OPEN_DATE',\n",
       "  'BIRTH_DATE'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.num_columns, myrdf.cat_columns, myrdf.date_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_date = myrdf['REPORTING_DATE'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrdf.date_to_int(reporting_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrdf.drop('REPORTING_DATE', inplace=True, axis=1)\n",
    "myrdf.num_columns.remove('REPORTING_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ORIGINAL_BOOKED_AMOUNT',\n",
       "  'OUTSTANDING',\n",
       "  'BUCKET',\n",
       "  'LOAN_OPEN_DATE',\n",
       "  'EXPECTED_CLOSE_DATE',\n",
       "  'CUSTOMER_OPEN_DATE',\n",
       "  'BIRTH_DATE'],\n",
       " ['PROGRAM_NAME', 'SEX', 'PROFESSION', 'CAR_TYPE'],\n",
       " 'None due to date_to_int method being called before.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.num_columns, myrdf.cat_columns, myrdf.date_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.18</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>88223.40</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.84</td>\n",
       "      <td>33.45</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>KIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.74</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>33714.82</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.75</td>\n",
       "      <td>34.05</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>CARRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>3.67</td>\n",
       "      <td>34.18</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>CHEVROLET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>99054.45</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.86</td>\n",
       "      <td>40.68</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>94250.0</td>\n",
       "      <td>89450.17</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.82</td>\n",
       "      <td>42.63</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>SEAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PROGRAM_NAME  LOAN_OPEN_DATE  \\\n",
       "0       Auto Loans 50% Down Payment - Employed            3.76   \n",
       "1                     Pick Up and Small Trucks            3.73   \n",
       "2       Auto Loans 40% Down Payment - Employed            3.63   \n",
       "3  Auto Loans 30% Down Payment - Self Employed            3.77   \n",
       "4  Auto Loans 30% Down Payment - Self Employed            3.77   \n",
       "\n",
       "   EXPECTED_CLOSE_DATE  ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  BUCKET SEX  \\\n",
       "0                 1.18                 91000.0     88223.40       0   M   \n",
       "1                 1.74                 35000.0     33714.82       0   M   \n",
       "2                 1.35                 52500.0     52500.00       0   F   \n",
       "3                 0.10                103000.0     99054.45       0   M   \n",
       "4                 0.82                 94250.0     89450.17       0   M   \n",
       "\n",
       "   CUSTOMER_OPEN_DATE  BIRTH_DATE  PROFESSION    CAR_TYPE  \n",
       "0                3.84       33.45    EMPLOYEE         KIA  \n",
       "1                3.75       34.05    EMPLOYEE       CARRY  \n",
       "2                3.67       34.18   HOUSEWIFE   CHEVROLET  \n",
       "3                3.86       40.68  Shop Owner  MITSUBISHI  \n",
       "4                3.82       42.63  Shop Owner        SEAT  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implement the following 2 methods to automate the Risk-based segmentation process:\n",
    "* You can implement more methods if you think it is necessary.\n",
    "* In computer science, when we are dividing the code it is important to think which code does what. For example, __data cleanning__ and __data preparation__, is it done by the Risk Based Segmentation Class or the class assumes that the data is clean and ready for modelling (all variables are numeric, and dummies are already provided)?\n",
    "* Use: the input dataset should already be clean and ready for the trainning of a Logistic Regression with a binary target 0 and 1 class. \n",
    "* Scope: data cleanning and data preparation is out of the scope of the Class, but notice that .missing_not_at_random() requires the data to have missing values.\n",
    "\n",
    "## 1) Implement a method .missing_not_at_random() \n",
    "To identify different potential segments sharing data (based on sharing missing values) - Expected result is a print:\n",
    "Missing Not At Random Repport (MNAR) -  PROFESSION, SEX and BIRTH_DATE variables seem Missing Not at Random, there for we recommend:\n",
    "\n",
    "&emsp;  Thin File Segment Variables (all others variables free of MNAR issue): REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, \n",
    "OUTSTANDING, CUSTOMER_OPEN_DATE, CAR_TYPE\n",
    "\n",
    "&emsp; Full File Segment Variables: REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, OUTSTANDING, SEX, CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Must run the missing_not_at_random method to update this attribute'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.mnra_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Not At Random Repport - ['PROFESSION', 'SEX', 'BIRTH_DATE'] variables seem Missing Not at Random,there for we recommend:\n",
      "Thin File Segment Variables: ['ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING', 'BUCKET', 'LOAN_OPEN_DATE', 'EXPECTED_CLOSE_DATE', 'CUSTOMER_OPEN_DATE', 'PROGRAM_NAME', 'CAR_TYPE']\n",
      "Full File Segment Variables: ['ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING', 'BUCKET', 'LOAN_OPEN_DATE', 'EXPECTED_CLOSE_DATE', 'CUSTOMER_OPEN_DATE', 'BIRTH_DATE', 'PROGRAM_NAME', 'SEX', 'PROFESSION', 'CAR_TYPE']\n"
     ]
    }
   ],
   "source": [
    "myrdf.missing_not_at_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROFESSION', 'SEX', 'BIRTH_DATE']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.mnra_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "OUTPUT SAMPLE:\n",
    "\n",
    "__Missing Not At Random Repport__ -  REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID variables seem Missing Not at Random, there for we recommend:\n",
    "\n",
    "&emsp;  Thin File Segment Variables: PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, \n",
    "ORIGINAL_BOOKED_AMOUNT, OUTSTANDING, SEX, \n",
    "CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "&emsp; Full File Segment Variables: REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, \n",
    "OUTSTANDING, SEX, CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\t2) implement a method .find_segment_split(variable)\n",
    "given one variable, implement a method to identify if the variable is a good segmentation splitter and if the variable is a good splitter,   \n",
    "different segments of customers with different level of risk (the one explained in the second video)\n",
    "* Scope: data cleanning and data preparation is out of the scope of the Class, note that .find_segment_split(VARIABLE) assumes the data is already clean free of missing values.\n",
    "* Categorical: for the segmentation process of categorical variable, dummy transformation is not practical, it is recommended that categorical variables come pre-transformed into numerical by replacing the categories by the Probability of belonging to class 1.\n",
    "* The following code only works for a single variable, implement a loop going over each variable of the dataset as a candidate for segmentation.\n",
    "* The following method must implement two segmentation approaches, one for Categorical Nominal (order not relevant - variable must be automatically transformed) and others where order is important.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PROGRAM_NAME              0.000000\n",
       " LOAN_OPEN_DATE            0.000000\n",
       " EXPECTED_CLOSE_DATE       0.000000\n",
       " ORIGINAL_BOOKED_AMOUNT    0.000000\n",
       " OUTSTANDING               0.000000\n",
       " BUCKET                    0.000000\n",
       " SEX                       0.505170\n",
       " CUSTOMER_OPEN_DATE        0.000000\n",
       " BIRTH_DATE                0.505731\n",
       " PROFESSION                0.620796\n",
       " CAR_TYPE                  1.295115\n",
       " dtype: float64,\n",
       " (900860, 11))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.isna().sum()/myrdf.count()*100 , myrdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>88223.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.84</td>\n",
       "      <td>33.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>CARRY</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>33714.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.75</td>\n",
       "      <td>34.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52500.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.67</td>\n",
       "      <td>34.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>99054.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.86</td>\n",
       "      <td>40.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>SEAT</td>\n",
       "      <td>94250.0</td>\n",
       "      <td>89450.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.82</td>\n",
       "      <td>42.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PROGRAM_NAME SEX  PROFESSION    CAR_TYPE  \\\n",
       "0       Auto Loans 50% Down Payment - Employed   M    EMPLOYEE         KIA   \n",
       "1                     Pick Up and Small Trucks   M    EMPLOYEE       CARRY   \n",
       "2       Auto Loans 40% Down Payment - Employed   F   HOUSEWIFE   CHEVROLET   \n",
       "3  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner  MITSUBISHI   \n",
       "4  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner        SEAT   \n",
       "\n",
       "   ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  BUCKET  LOAN_OPEN_DATE  \\\n",
       "0                 91000.0     88223.40     0.0            3.76   \n",
       "1                 35000.0     33714.82     0.0            3.73   \n",
       "2                 52500.0     52500.00     0.0            3.63   \n",
       "3                103000.0     99054.45     0.0            3.77   \n",
       "4                 94250.0     89450.17     0.0            3.77   \n",
       "\n",
       "   EXPECTED_CLOSE_DATE  CUSTOMER_OPEN_DATE  BIRTH_DATE  \n",
       "0                 1.18                3.84       33.45  \n",
       "1                 1.74                3.75       34.05  \n",
       "2                 1.35                3.67       34.18  \n",
       "3                 0.10                3.86       40.68  \n",
       "4                 0.82                3.82       42.63  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "df_cat = pd.DataFrame(cat_imputer.fit_transform(myrdf[myrdf.cat_columns]))\n",
    "df_cat.columns = myrdf.cat_columns\n",
    "df_num = pd.DataFrame(num_imputer.fit_transform(myrdf[myrdf.num_columns]))\n",
    "df_num.columns = myrdf.num_columns\n",
    "\n",
    "\n",
    "df = df_cat\n",
    "df = df.join(df_num)\n",
    "myrdf = rdf.RiskDataframe(df)\n",
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PROGRAM_NAME              0.0\n",
       " SEX                       0.0\n",
       " PROFESSION                0.0\n",
       " CAR_TYPE                  0.0\n",
       " ORIGINAL_BOOKED_AMOUNT    0.0\n",
       " OUTSTANDING               0.0\n",
       " BUCKET                    0.0\n",
       " LOAN_OPEN_DATE            0.0\n",
       " EXPECTED_CLOSE_DATE       0.0\n",
       " CUSTOMER_OPEN_DATE        0.0\n",
       " BIRTH_DATE                0.0\n",
       " dtype: float64,\n",
       " (900860, 11))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.isna().sum()/myrdf.count()*100 , myrdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    743348\n",
       "1.0    100979\n",
       "2.0     35120\n",
       "3.0     11306\n",
       "4.0      4981\n",
       "5.0      2627\n",
       "7.0      1457\n",
       "6.0      1042\n",
       "Name: BUCKET, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf['BUCKET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>BUCKET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>88223.40</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.84</td>\n",
       "      <td>33.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>CARRY</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>33714.82</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.75</td>\n",
       "      <td>34.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52500.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.67</td>\n",
       "      <td>34.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>99054.45</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.86</td>\n",
       "      <td>40.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>SEAT</td>\n",
       "      <td>94250.0</td>\n",
       "      <td>89450.17</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.82</td>\n",
       "      <td>42.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PROGRAM_NAME SEX  PROFESSION    CAR_TYPE  \\\n",
       "0       Auto Loans 50% Down Payment - Employed   M    EMPLOYEE         KIA   \n",
       "1                     Pick Up and Small Trucks   M    EMPLOYEE       CARRY   \n",
       "2       Auto Loans 40% Down Payment - Employed   F   HOUSEWIFE   CHEVROLET   \n",
       "3  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner  MITSUBISHI   \n",
       "4  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner        SEAT   \n",
       "\n",
       "   ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  LOAN_OPEN_DATE  EXPECTED_CLOSE_DATE  \\\n",
       "0                 91000.0     88223.40            3.76                 1.18   \n",
       "1                 35000.0     33714.82            3.73                 1.74   \n",
       "2                 52500.0     52500.00            3.63                 1.35   \n",
       "3                103000.0     99054.45            3.77                 0.10   \n",
       "4                 94250.0     89450.17            3.77                 0.82   \n",
       "\n",
       "   CUSTOMER_OPEN_DATE  BIRTH_DATE  BUCKET  \n",
       "0                3.84       33.45       0  \n",
       "1                3.75       34.05       0  \n",
       "2                3.67       34.18       0  \n",
       "3                3.86       40.68       0  \n",
       "4                3.82       42.63       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'BUCKET'\n",
    "target_series = myrdf[target]\n",
    "myrdf = myrdf.drop(target, axis=1)\n",
    "target_array = np.vectorize(lambda x: 0 if x == 0 else 1)(target_series)\n",
    "target_df = pd.DataFrame(target_array)\n",
    "target_df = target_df.rename(columns={0:'BUCKET'}) \n",
    "\n",
    "\n",
    "myrdf = myrdf.join(target_df)\n",
    "myrdf.num_columns.append(target)\n",
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    743348\n",
       "1    157512\n",
       "Name: BUCKET, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf['BUCKET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>BUCKET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>88223.40</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.84</td>\n",
       "      <td>33.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>CARRY</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>33714.82</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.75</td>\n",
       "      <td>34.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52500.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.67</td>\n",
       "      <td>34.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>99054.45</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.86</td>\n",
       "      <td>40.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>SEAT</td>\n",
       "      <td>94250.0</td>\n",
       "      <td>89450.17</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.82</td>\n",
       "      <td>42.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PROGRAM_NAME SEX  PROFESSION    CAR_TYPE  \\\n",
       "0       Auto Loans 50% Down Payment - Employed   M    EMPLOYEE         KIA   \n",
       "1                     Pick Up and Small Trucks   M    EMPLOYEE       CARRY   \n",
       "2       Auto Loans 40% Down Payment - Employed   F   HOUSEWIFE   CHEVROLET   \n",
       "3  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner  MITSUBISHI   \n",
       "4  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner        SEAT   \n",
       "\n",
       "   ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  LOAN_OPEN_DATE  EXPECTED_CLOSE_DATE  \\\n",
       "0                 91000.0     88223.40            3.76                 1.18   \n",
       "1                 35000.0     33714.82            3.73                 1.74   \n",
       "2                 52500.0     52500.00            3.63                 1.35   \n",
       "3                103000.0     99054.45            3.77                 0.10   \n",
       "4                 94250.0     89450.17            3.77                 0.82   \n",
       "\n",
       "   CUSTOMER_OPEN_DATE  BIRTH_DATE  BUCKET  \n",
       "0                3.84       33.45       0  \n",
       "1                3.75       34.05       0  \n",
       "2                3.67       34.18       0  \n",
       "3                3.86       40.68       0  \n",
       "4                3.82       42.63       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Must run the find_segmentation_split method to update this attribute'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.accuracy_fitted_full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL_BOOKED_AMOUNT: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on ORIGINAL_BOOKED_AMOUNT Seg 1 (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 1 (test sample): 0.238 %\n",
      "Model Developed on Full Population (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 1 (test sample): 0.238 %\n",
      "Model Developed on ORIGINAL_BOOKED_AMOUNT Seg 2 (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 2 (test sample): 0.265 %\n",
      "Model Developed on Full Population (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 2 (test sample): 0.265 %\n",
      "OUTSTANDING: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on OUTSTANDING Seg 1 (train sample) applied on OUTSTANDING Seg 1 (test sample): 0.256 %\n",
      "Model Developed on Full Population (train sample) applied on OUTSTANDING Seg 1 (test sample): 0.256 %\n",
      "Model Developed on OUTSTANDING Seg 2 (train sample) applied on OUTSTANDING Seg 2 (test sample): 0.256 %\n",
      "Model Developed on Full Population (train sample) applied on OUTSTANDING Seg 2 (test sample): 0.256 %\n",
      "LOAN_OPEN_DATE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on LOAN_OPEN_DATE Seg 1 (train sample) applied on LOAN_OPEN_DATE Seg 1 (test sample): 0.22 %\n",
      "Model Developed on Full Population (train sample) applied on LOAN_OPEN_DATE Seg 1 (test sample): 0.22 %\n",
      "Model Developed on LOAN_OPEN_DATE Seg 2 (train sample) applied on LOAN_OPEN_DATE Seg 2 (test sample): 0.213 %\n",
      "Model Developed on Full Population (train sample) applied on LOAN_OPEN_DATE Seg 2 (test sample): 0.213 %\n",
      "EXPECTED_CLOSE_DATE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on EXPECTED_CLOSE_DATE Seg 1 (train sample) applied on EXPECTED_CLOSE_DATE Seg 1 (test sample): 0.249 %\n",
      "Model Developed on Full Population (train sample) applied on EXPECTED_CLOSE_DATE Seg 1 (test sample): 0.249 %\n",
      "Model Developed on EXPECTED_CLOSE_DATE Seg 2 (train sample) applied on EXPECTED_CLOSE_DATE Seg 2 (test sample): 0.255 %\n",
      "Model Developed on Full Population (train sample) applied on EXPECTED_CLOSE_DATE Seg 2 (test sample): 0.255 %\n",
      "CUSTOMER_OPEN_DATE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on CUSTOMER_OPEN_DATE Seg 1 (train sample) applied on CUSTOMER_OPEN_DATE Seg 1 (test sample): 0.254 %\n",
      "Model Developed on Full Population (train sample) applied on CUSTOMER_OPEN_DATE Seg 1 (test sample): 0.254 %\n",
      "Model Developed on CUSTOMER_OPEN_DATE Seg 2 (train sample) applied on CUSTOMER_OPEN_DATE Seg 2 (test sample): 0.203 %\n",
      "Model Developed on Full Population (train sample) applied on CUSTOMER_OPEN_DATE Seg 2 (test sample): 0.203 %\n",
      "BIRTH_DATE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on BIRTH_DATE Seg 1 (train sample) applied on BIRTH_DATE Seg 1 (test sample): 0.278 %\n",
      "Model Developed on Full Population (train sample) applied on BIRTH_DATE Seg 1 (test sample): 0.278 %\n",
      "Model Developed on BIRTH_DATE Seg 2 (train sample) applied on BIRTH_DATE Seg 2 (test sample): 0.223 %\n",
      "Model Developed on Full Population (train sample) applied on BIRTH_DATE Seg 2 (test sample): 0.223 %\n",
      "PROGRAM_NAME: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on PROGRAM_NAME Seg 1 (train sample) applied on PROGRAM_NAME Seg 1 (test sample): 0.291 %\n",
      "Model Developed on Full Population (train sample) applied on PROGRAM_NAME Seg 1 (test sample): 0.291 %\n",
      "Model Developed on PROGRAM_NAME Seg 2 (train sample) applied on PROGRAM_NAME Seg 2 (test sample): 0.196 %\n",
      "Model Developed on Full Population (train sample) applied on PROGRAM_NAME Seg 2 (test sample): 0.196 %\n",
      "SEX: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on SEX Seg 1 (train sample) applied on SEX Seg 1 (test sample): 0.248 %\n",
      "Model Developed on Full Population (train sample) applied on SEX Seg 1 (test sample): 0.248 %\n",
      "Model Developed on SEX Seg 2 (train sample) applied on SEX Seg 2 (test sample): 0.265 %\n",
      "Model Developed on Full Population (train sample) applied on SEX Seg 2 (test sample): 0.265 %\n",
      "PROFESSION: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on PROFESSION Seg 1 (train sample) applied on PROFESSION Seg 1 (test sample): 0.268 %\n",
      "Model Developed on Full Population (train sample) applied on PROFESSION Seg 1 (test sample): 0.268 %\n",
      "Model Developed on PROFESSION Seg 2 (train sample) applied on PROFESSION Seg 2 (test sample): 0.253 %\n",
      "Model Developed on Full Population (train sample) applied on PROFESSION Seg 2 (test sample): 0.253 %\n",
      "CAR_TYPE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on CAR_TYPE Seg 1 (train sample) applied on CAR_TYPE Seg 1 (test sample): 0.255 %\n",
      "Model Developed on Full Population (train sample) applied on CAR_TYPE Seg 1 (test sample): 0.255 %\n",
      "Model Developed on CAR_TYPE Seg 2 (train sample) applied on CAR_TYPE Seg 2 (test sample): 0.246 %\n",
      "Model Developed on Full Population (train sample) applied on CAR_TYPE Seg 2 (test sample): 0.246 %\n"
     ]
    }
   ],
   "source": [
    "myrdf.find_segment_split(target='BUCKET', robust_scaler='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>0.712837</td>\n",
       "      <td>-0.121547</td>\n",
       "      <td>-0.039735</td>\n",
       "      <td>-0.158654</td>\n",
       "      <td>-0.428502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.826531</td>\n",
       "      <td>-0.260049</td>\n",
       "      <td>-0.138122</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>-0.201923</td>\n",
       "      <td>-0.389547</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.469388</td>\n",
       "      <td>0.075235</td>\n",
       "      <td>-0.193370</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>-0.240385</td>\n",
       "      <td>-0.381107</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.906153</td>\n",
       "      <td>-0.116022</td>\n",
       "      <td>-0.754967</td>\n",
       "      <td>-0.149038</td>\n",
       "      <td>0.040902</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.382653</td>\n",
       "      <td>0.734733</td>\n",
       "      <td>-0.116022</td>\n",
       "      <td>-0.278146</td>\n",
       "      <td>-0.168269</td>\n",
       "      <td>0.167505</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BUCKET  ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  LOAN_OPEN_DATE  \\\n",
       "0       0                0.316327     0.712837       -0.121547   \n",
       "1       0               -0.826531    -0.260049       -0.138122   \n",
       "2       0               -0.469388     0.075235       -0.193370   \n",
       "3       0                0.561224     0.906153       -0.116022   \n",
       "4       0                0.382653     0.734733       -0.116022   \n",
       "\n",
       "   EXPECTED_CLOSE_DATE  CUSTOMER_OPEN_DATE  BIRTH_DATE  PROGRAM_NAME  SEX  \\\n",
       "0            -0.039735           -0.158654   -0.428502      0.000000  0.0   \n",
       "1             0.331126           -0.201923   -0.389547      2.500000  0.0   \n",
       "2             0.072848           -0.240385   -0.381107     -0.333333 -1.0   \n",
       "3            -0.754967           -0.149038    0.040902     -0.833333  0.0   \n",
       "4            -0.278146           -0.168269    0.167505     -0.833333  0.0   \n",
       "\n",
       "   PROFESSION  CAR_TYPE  \n",
       "0    0.000000  0.227273  \n",
       "1    0.000000 -0.909091  \n",
       "2    0.181818 -0.772727  \n",
       "3    2.363636  0.636364  \n",
       "4    2.363636  1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8240681126923163"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.accuracy_fitted_full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "## Mandatory (part 1 - p1) -  Implement the following: (5 out of 10 points)\n",
    "\n",
    "- __Project Name__: pick a name for your project (if it is taken at https://pypi.org/ please create small variations), I recommend you get inspiration by the following Pockemon names: some_pockemon_examples.zip\n",
    "\n",
    "- __Project Managment (Github)__: Work in group using Github, invite professor manoelgad@gmail.com as a collaborator to your project from the very beggining.\n",
    "\n",
    "- __Implementation__: Discuss in group and decide the implementation you need to do for each method (missing_not_at_random and find_segment_split), then do the implementation of missing_not_at_random and find_segment_split. Your implementation should work in any dataset (make the necessary assumption and inform the user if the assumption are not followed, for example: inform the dataset must be clean and types must be informed in case they are not). \n",
    "\n",
    "- __Video__: Create a video from 5 to 15 minutes explainning the whole library (including p1 and p2) and showing examples of how to use it. The video will not be assessed own its own and won't be assessed by colleagues. The video can be very simple, just the notebook/python class and someone explainning things. Upload the video to Youtube and include a link to the video in the website if your group decide to pick Publishing below.    \n",
    "\n",
    "\n",
    "## Improvements (part 2 - p2) -  Implement 2 of the following list of tasks:  (5 out of 10 points)\n",
    "\n",
    "- __Improving__: Make improvements to the code -  Reliable/Robust: Create a train-test split, train all models in train and test all models always in test; Robust: Research and apply a statistical test to decide when the accuracy diffrence in statiscally relevant. Small functions/methods: Break your implementation into small functions/methods; Fast: Optimize your code, use vectorization when possible. Use stratified random sampling to reduce dataset sizes and therefore speed up the segmentation process. Implement segmentation split using Tree algorithm.\n",
    "\n",
    "- __Publishing__: Publish your code in GitHub -  Work in group using Github, invite professor manoelgad@gmail.com as a collaborator to your project from the very beggining. Create a python package and distribute your package using https://pypi.org/, by the end of the project one must be able to pip install your project and use it.\n",
    "References: https://www.youtube.com/watch?v=GIF3LaRqgXo; and  https://github.com/judy2k/publishing_python_packages_talk\n",
    "\n",
    "- __Testing__: Implement a Test class using unittest with an \"comprehensive\" set of tests using a series of datasets of your choice. Have a look at this: https://ains.co/blog/things-which-arent-magic-flask-part-1.html and https://www.youtube.com/watch?v=1Lfv5tUGsn8\n",
    "\n",
    "- __Documentation__: create a documentation for your project and publish it at GitHub project (readme) and also a pythonanywhere.com website (simple HTML). The documentation must contain an about, a how to and also examples of how to use with one or more datasets. All used datasets should be provided within the project (make sure you don't share huge datasets, make it small before sharing your code).\n",
    "\n",
    "- __Logging & Repporting__: Log all intermediate results and final results into a Sqlite database using SQLAlchemy, then produce the final result repport in HTML format using Bokeh.\n",
    "\n",
    "\n",
    "# Evaluation criteria\n",
    "\n",
    "All team members have the choice of focusing, by choising 1 or 2 of the tasks of part 2.\n",
    "*   If 1 task of part 2 is choosen, grade will be: p1\\*0.5 + p2x\\*0.4 + (p2y\\*0.1) (p2x is the grade in the choosen task and p2y the other) \n",
    "*   If 2 tasks of part 2 are choosen, grade will be: p1\\*0.5 + (p2x\\*0.25 + p2y\\*0.25)\n",
    "* If your group only implement 1 extra part, all members will be assessed using: p1\\*0.5 + p2x\\*0.4 + (p2y\\*0.1)\n",
    "* If your group implements more then 2 parts, please indicate the ones you want to be assessed upon.\n",
    "\n",
    "\n",
    "What professor will look at when assessing the project:\n",
    "*\tProblem structuring - How did you structure the problem and the project?\n",
    "*\tWhat assumptions did you make? (Please mention them in the video)\n",
    "*\tHow did you narrow the scope? (Please mention them in the video)\n",
    "*\tTechnical Skills: How reliable (does it use your own class? does is it apply data quality controls?)), readable and flexible (can you apply your code to a new dataset?) was the code that you developed?\n",
    "* Analytical Skills: How logically sound, complete and meaningful was the approach (machine learning, statistics, analytics, visualizationâ€¦) that you applied?\n",
    "*\tUsefulness:\tHow useful would the results of your work for new datasets?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "You are allowed to use __Python only__ and any Python Library inside your Jupyter Notebook or inside your Class, always give preference to Pandas and Scikit Learn whenever you can.\n",
    "\n",
    "\n",
    "\n",
    "# Deliverables\n",
    "*\tA zip file with all code and datasets used for the projet.\n",
    "\n",
    "\n",
    "# Data description\n",
    "We will provide you with historical data of car loans. The data contains monthly status for each loan for 3 years. In addition to some demographic information\n",
    "\n",
    "# Notes:\n",
    "*\tThis data is Loan level NOT Customer level, meaning that one customer can take more than one loan\n",
    "*\tThe data is monthly starting from 2016-01-01 to 2019-09-01 so if the loan already started before Jan2016 you will find partial history for it.\n",
    "*\tWe have multiple programs under the car loans product\n",
    "*\tMake sure you understand the difference between Buckets\n",
    "\n",
    "# Research:\n",
    "In order to implement the methods missing_not_at_random and find_segment_split, you are allowed to search for whichever information you need in the internet including but not limited to:\n",
    "*\tCode syntax\n",
    "*\tBusiness term (However you can ask me)\n",
    "\n",
    "Start by looking into these 3 videos:\n",
    "*\tWhat is Risk-based segmentation? https://www.youtube.com/watch?v=2ZpLgUcucfQ \n",
    "*   This is a generic video on Segmentation, it is a good reference, but careful not all needs to be implemented and not all mentioned here is relevant for this project: https://www.youtube.com/watch?v=PLsUfDDytaE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX: \n",
    "\n",
    "## Simple example of Risk Based Segmentation\n",
    "\n",
    "*   Video explainning the code below: https://www.youtube.com/watch?v=kWtnlpGwh_o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-eb82507083f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;31m#pd.read_csv(\"AUTO_LOANS_DATA.csv\", sep=\";\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "df = dataframe#pd.read_csv(\"AUTO_LOANS_DATA.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argument_dict = {'REPORTING_DATE':'datetime64[ns]','LOAN_OPEN_DATE':'datetime64[ns]',\n",
    "                 'EXPECTED_CLOSE_DATE':'datetime64[ns]','CUSTOMER_OPEN_DATE':'datetime64[ns]',\n",
    "                 'BIRTH_DATE':'datetime64[ns]','PROGRAM_NAME':'category','BUCKET':'category','SEX':'category',\n",
    "                'PROFESSION':'category','CAR_TYPE':'category'}\n",
    "myrdf.SetAttributes(argument_dict)\n",
    "myrdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sample trick to speed up the process..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = dataframe\n",
    "df_random_sample, _ = train_test_split(dataframe, test_size=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirty variable selection, feature transformation and data cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_columns(df, data_types, to_ignore = list(), ignore_target = False):\n",
    "    columns = df.select_dtypes(include=data_types).columns\n",
    "    if ignore_target:\n",
    "        columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "    return list(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'BINARIZED_TARGET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_numeric_variables = get_specific_columns(df, [\"float64\", \"int64\"], [target], ignore_target = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression - Full Model - all variables\n",
    "You sould use LogisticRegression in the modeling part to avoid any overfitting issues, and also split your data into train and test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "splitter = train_test_split\n",
    "\"-----------------------\"\n",
    "\n",
    "df_train, df_test = splitter(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[all_numeric_variables]\n",
    "y_train = df_train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[all_numeric_variables]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "method = LogisticRegression(random_state=0)\n",
    "fitted_full_model = method.fit(X_train, y_train)\n",
    "y_pred = fitted_full_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINI vs Accuracy - use GINI for this analysis!\n",
    "\n",
    "GINI as well as accuracy is a 0 to 1 measure, 0 being very bad prediction and 1 being perfect separation.\n",
    "For this project __you should use GINI__ as it looks the model in all predictions (all range of probabilities), accuracy gets the probability and using a cut-off and transform the probability into predicted class 0 for probabilities below 50% and predicted class 1 for above or equal to 50%. So using accuracy makes our analysis for segmentation very short sighted as the result of the analysis could change if one changes the cut-off to let say 40%, for this reason we will use the GINI coeficient which is independent of the cut-off having a better overview of the whole model predictions.\n",
    "\n",
    "GINI is a simple calculation resulting from AUC. You will not find directly the Gini Coefficient as an attribute for the LogisticRegressor Class, but you can use the 2*AUC-1 formula to calculate it. \n",
    "\n",
    "If you want more details about GINI have a look into this video:\n",
    "https://www.youtube.com/watch?v=MiBUBVUC8kE\n",
    "\n",
    "\n",
    "Make sure you use .predict_proba (to predict probability) and then get the first column using [:,1] to get only the probability of being 1, instead of .predict which gives the 0 or 1 class. This proba is  what you need to pass as predictions_list below, to finally obtain the GINI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probadbility = fitted_full_model.predict_proba(X_test)[:,1]\n",
    "#y_test is your actual 0 and 1 class and y_pred_probadbility is the predicted probability of belonging to class 1.\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probadbility)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "GINI = (2 * roc_auc) - 1\n",
    "print(GINI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Model 1 - Gender M and F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_seg1 = df_train[df['SEX'] == \"M\"]\n",
    "df_train_seg2 = df_train[df['SEX'] != \"M\"]\n",
    "df_test_seg1 = df_test[df['SEX'] == \"M\"]\n",
    "df_test_seg2 = df_test[df['SEX'] != \"M\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model vs Seg 1 on Seg 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seg1 = df_train_seg1[all_numeric_variables]\n",
    "y_train_seg1 = df_train_seg1[target]\n",
    "X_test_seg1 = df_test_seg1[all_numeric_variables]\n",
    "y_test_seg1 = df_test_seg1[target]\n",
    "fitted_model_seg1 = method.fit(X_train_seg1, y_train_seg1)\n",
    "\n",
    "def GINI(y_test, y_pred_probadbility):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probadbility)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    GINI = (2 * roc_auc) - 1\n",
    "    return(GINI)\n",
    "\n",
    "y_pred_seg1_proba = fitted_model_seg1.predict_proba(X_test_seg1)[:,1]\n",
    "y_pred_seg1_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg1)[:,1]\n",
    "\n",
    "print(\"Segment1: SEX in ('M') [GINI Full Model: {:.4f}% / GINI Segmented Model: {:.4f}%]\".format(\n",
    "    GINI(y_test_seg1, y_pred_seg1_proba)*100,\n",
    "    GINI(y_test_seg1, y_pred_seg1_fullmodel_proba)*100\n",
    ")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model vs Seg 2 on Seg 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seg2 = df_train_seg2[all_numeric_variables]\n",
    "y_train_seg2 = df_train_seg2[target]\n",
    "X_test_seg2 = df_test_seg2[all_numeric_variables]\n",
    "y_test_seg2 = df_test_seg2[target]\n",
    "fitted_model_seg2 = method.fit(X_train_seg2, y_train_seg2)\n",
    "\n",
    "y_pred_seg2_proba = fitted_model_seg2.predict_proba(X_test_seg2)[:,1]\n",
    "y_pred_seg2_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg2)[:,1]\n",
    "\n",
    "print(\"Segment1: SEX in ('F') [GINI Full Model: {:.4f}% / GINI Segmented Model: {:.4f}%]\".format(\n",
    "    GINI(y_test_seg2, y_pred_seg2_proba)*100,\n",
    "    GINI(y_test_seg2, y_pred_seg2_fullmodel_proba)*100\n",
    "))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Summary Repport\n",
    "\n",
    "&emsp;\n",
    "BUCKET is the target variable and was not analyzed separetly.\n",
    "\n",
    "__Missing Not At Random Repport__ -  REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID variables seem Missing Not at Random, there for we recommend:\n",
    "\n",
    "&emsp;  Thin File Segment Variables: PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, \n",
    "ORIGINAL_BOOKED_AMOUNT, OUTSTANDING, SEX, \n",
    "CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "&emsp; Full File Segment Variables: REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, \n",
    "OUTSTANDING, SEX, CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "__Variable by Variable Risk Based Segmentation Analysis__:\n",
    "\n",
    "&emsp; REPORTING_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; ACCOUNT_NUMBER Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CUSTOMER_ID Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; PROGRAM_NAME Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; LOAN_OPEN_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; EXPECTED_CLOSE_DATE Good for segmentation.  \n",
    "\n",
    "&emsp; &emsp; Segment1: EXPECTED_CLOSE_DATE < '22/07/2021'  [GINI Full Model: 32.1234% / GINI Segmented Model: 33.4342%]\n",
    "\n",
    "&emsp; &emsp;  Segment2: EXPECTED_CLOSE_DATE >= '22/07/2021' [GINI Full Model: 63.7523% / GINI Segmented Model: 68.8342%]\n",
    "\n",
    "&emsp; ORIGINAL_BOOKED_AMOUNT Good for segmentation.  \n",
    "\n",
    "&emsp; &emsp; Segment1: ORIGINAL_BOOKED_AMOUNT < 90000 [GINI Full Model: 32.3243% / GINI Segmented Model: 33.9833%]\n",
    "\n",
    "&emsp; &emsp; Segment2: ORIGINAL_BOOKED_AMOUNT >= 90000 [GINI Full Model: 63.3449% / GINI Segmented Model: 68.9438%]\n",
    "\n",
    "&emsp; OUTSTANDING Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; SEX Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CUSTOMER_OPEN_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CUSTOMER_OPEN_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; BIRTH_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; PROFESSION Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CAR_TYPE Good for segmentation.  \n",
    "\n",
    "&emsp; &emsp; Segment1: CAR_TYPE in (BMW', 'BYD', 'CARRY', 'Changan', 'CHEVROLET', 'Gelory', 'GELY', 'HYUNDAI') [GINI Full Model: 35.3492% / GINI Segmented Model: 37.3943%]\n",
    "\n",
    "&emsp; &emsp; Segment2: CAR_TYPE in ('Jack', 'KIA', 'MERCEDES', 'MITSUBISHI', 'NISSAN', 'RENAULT', 'SEAT', 'SKODA', 'SUZUKI') [GINI Full Model: 42.4324% / GINI Segmented Model: 49.4393%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
