{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project - Risk Based Segmentation \n",
    "\n",
    "This is document contains a description of the task and also a starter code. \n",
    "Implement your exercise by changing only this Jupyter Notebook and the class inside RiskDataFrame.py, deliver both files. \n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Customer segmentation involves categorizing the portfolio by industry, location, revenue, account size, and number of employees and many other variables to reveal where risk and opportunity live within the portfolio. Those patterns can then provide key measurable data points for more predictive credit risk management. Taking a portfolio approach to risk management gives credit professionals a better fix on the accounts, in order to develop strategies for better serving segments that present the best opportunities. Not only that, you can work to maximize performance\n",
    "in all customer segments, even seemingly risky segments.\n",
    "\n",
    "Customer segmentation analysis can lead to several tangible improvements in credit risk management: stronger credit policies, and improved internal communication and cooperation across teams.\n",
    "\n",
    "## Task scope\n",
    "Your group is working in the retail risk modeling team and you are asked to build a class to perform risk-based segmentation and test it for car loansâ€™ customers based on given historical data of customer behavior. The class must perform the segmentation from a risk management perspective.\n",
    "\n",
    "## Class\n",
    "We will use Nico's great initial code, which extends Pandas DataFrame in a magical way turning our own class into like-Pandas:\n",
    "\n",
    "    #Initializing the inherited pd.DataFrame\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "    \n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        def func_(*args,**kwargs):\n",
    "            df = RiskDataframe(*args,**kwargs)\n",
    "            return df\n",
    "        return func_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORM YOUR OWN DATA CLEANNING & DATA PREPARATION HERE\n",
    "\n",
    "Your objective in this part is simply to prepare the data to apply to the missing_not_at_random and find_segment_split\n",
    "methods. Do not overcomplicate the data cleanning and data preparation. Keep it simple!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages including periculum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Periculum_Group_B_IE import RiskDataframe as rdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\setej\\Documents\\IE Masters\\Python 2\\Group Project\\spp2_GroupProject_RBASegmentation\\AUTO_LOANS_DATA.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing account number and costumer id as no value in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ACCOUNT_NUMBER', 'CUSTOMER_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciatate the RiskDataframe class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The RiskDataframes init method:\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cat_columns = []\n",
    "        self.num_columns = []\n",
    "        self.date_columns = []\n",
    "        self.mnra_columns = 'Must run the missing_not_at_random method to update this attribute'\n",
    "        self.full_file_segment_variable = 'Must run the missing_not_at_random method to update this attribute'\n",
    "        self.thin_file_segment_variable = 'Must run the missing_not_at_random method to update this attribute'\n",
    "        self.GINI_fitted_full_model = 'Must run the find_segmentation_split method to update this attribute'\n",
    "        self.accuracy_fitted_full_model = 'Must run the find_segmentation_split method to update this attribute'\n",
    "        self.variable_split = 'Must run the find_segment_split method to update this attribute'\n",
    "        self.date_types()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrdf = rdf.RiskDataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the class inherited the Pandas dataframe attributes, and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REPORTING_DATE', 'PROGRAM_NAME', 'LOAN_OPEN_DATE',\n",
       "       'EXPECTED_CLOSE_DATE', 'ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING',\n",
       "       'BUCKET', 'SEX', 'CUSTOMER_OPEN_DATE', 'BIRTH_DATE', 'PROFESSION',\n",
       "       'CAR_TYPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPORTING_DATE</th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>2015-11-25</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>88223.40</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>1986-03-24</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>KIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>33714.82</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1985-08-18</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>CARRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>1985-07-02</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>CHEVROLET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>99054.45</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>94250.0</td>\n",
       "      <td>89450.17</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>1977-01-20</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>SEAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REPORTING_DATE                                 PROGRAM_NAME LOAN_OPEN_DATE  \\\n",
       "0     2016-01-31       Auto Loans 50% Down Payment - Employed     2015-11-25   \n",
       "1     2016-01-31                     Pick Up and Small Trucks     2015-12-08   \n",
       "2     2016-01-31       Auto Loans 40% Down Payment - Employed     2016-01-12   \n",
       "3     2016-01-31  Auto Loans 30% Down Payment - Self Employed     2015-11-23   \n",
       "4     2016-01-31  Auto Loans 30% Down Payment - Self Employed     2015-11-23   \n",
       "\n",
       "  EXPECTED_CLOSE_DATE  ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  BUCKET SEX  \\\n",
       "0          2020-11-03                 91000.0     88223.40       0   M   \n",
       "1          2017-12-03                 35000.0     33714.82       0   M   \n",
       "2          2021-01-03                 52500.0     52500.00       0   F   \n",
       "3          2019-10-03                103000.0     99054.45       0   M   \n",
       "4          2018-11-03                 94250.0     89450.17       0   M   \n",
       "\n",
       "  CUSTOMER_OPEN_DATE BIRTH_DATE  PROFESSION    CAR_TYPE  \n",
       "0         2015-10-27 1986-03-24    EMPLOYEE         KIA  \n",
       "1         2015-11-29 1985-08-18    EMPLOYEE       CARRY  \n",
       "2         2015-12-28 1985-07-02   HOUSEWIFE   CHEVROLET  \n",
       "3         2015-10-21 1979-01-01  Shop Owner  MITSUBISHI  \n",
       "4         2015-11-02 1977-01-20  Shop Owner        SEAT  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_types method is called in the instantiation of the class as a way to give the object the necessary attributes for the other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    def date_types(self):\n",
    "        \"\"\"\n",
    "        This method is used as a way to create a list for each column types,\n",
    "        in order to use these lists in further methods that will be called.\n",
    "        Since this method is necessary for the other methods in the class,\n",
    "        it is called when the class is instantiated.\n",
    "        \"\"\"\n",
    "        for column in self.columns:\n",
    "            if self[column].dtype == 'O':\n",
    "                self.cat_columns.append(column)\n",
    "            elif self[column].dtype == 'float64':\n",
    "                self.num_columns.append(column)\n",
    "            elif self[column].dtype == 'int64':\n",
    "                self.num_columns.append(column)\n",
    "            elif self[column].dtype == '<M8[ns]':\n",
    "                self.date_columns.append(column)\n",
    "            else:\n",
    "                None\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING', 'BUCKET'],\n",
       " ['PROGRAM_NAME', 'SEX', 'PROFESSION', 'CAR_TYPE'],\n",
       " ['REPORTING_DATE',\n",
       "  'LOAN_OPEN_DATE',\n",
       "  'EXPECTED_CLOSE_DATE',\n",
       "  'CUSTOMER_OPEN_DATE',\n",
       "  'BIRTH_DATE'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.num_columns, myrdf.cat_columns, myrdf.date_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_to_int method is an option method that will take any date columns and convert them to timedelta numbers as fraction of a year, using the parameter report_date as a required argument to calculate the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    def date_to_int(self, reporting_date):\n",
    "        \"\"\"\n",
    "        This is an optional method in case the data in the dataframe has date columns,\n",
    "        this method will convert all the dates to year fraction from the reporting date\n",
    "        to calculate the time difference. Which is necessary for the application of the\n",
    "        segmentation method, because Sklearn logistic regression does not accept date type\n",
    "        values.\n",
    "        ----------\n",
    "        reporting_date : This variable is a datetime object that will be the point in time\n",
    "        where all of the timedelta's will be calculated from.\n",
    "        -------\n",
    "        \"\"\"\n",
    "        for column in self.columns:\n",
    "            if self[column].dtype == '<M8[ns]':\n",
    "                self[column] = abs(self[column] - reporting_date).astype('timedelta64[D]')\n",
    "                self[column] = round(self[column] / 365, 2)\n",
    "            else:\n",
    "                pass\n",
    "        self.num_columns = self.num_columns + self.date_columns\n",
    "        self.date_columns = \"None due to date_to_int method being called before.\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_date = myrdf['REPORTING_DATE'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrdf.date_to_int(reporting_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping reporting date column, and remoove it from the num_columns attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrdf.drop('REPORTING_DATE', inplace=True, axis=1)\n",
    "myrdf.num_columns.remove('REPORTING_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ORIGINAL_BOOKED_AMOUNT',\n",
       "  'OUTSTANDING',\n",
       "  'BUCKET',\n",
       "  'LOAN_OPEN_DATE',\n",
       "  'EXPECTED_CLOSE_DATE',\n",
       "  'CUSTOMER_OPEN_DATE',\n",
       "  'BIRTH_DATE'],\n",
       " ['PROGRAM_NAME', 'SEX', 'PROFESSION', 'CAR_TYPE'],\n",
       " 'None due to date_to_int method being called before.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.num_columns, myrdf.cat_columns, myrdf.date_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.18</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>88223.40</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.84</td>\n",
       "      <td>33.45</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>KIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.74</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>33714.82</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.75</td>\n",
       "      <td>34.05</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>CARRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>3.67</td>\n",
       "      <td>34.18</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>CHEVROLET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>99054.45</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.86</td>\n",
       "      <td>40.68</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>94250.0</td>\n",
       "      <td>89450.17</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.82</td>\n",
       "      <td>42.63</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>SEAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PROGRAM_NAME  LOAN_OPEN_DATE  \\\n",
       "0       Auto Loans 50% Down Payment - Employed            3.76   \n",
       "1                     Pick Up and Small Trucks            3.73   \n",
       "2       Auto Loans 40% Down Payment - Employed            3.63   \n",
       "3  Auto Loans 30% Down Payment - Self Employed            3.77   \n",
       "4  Auto Loans 30% Down Payment - Self Employed            3.77   \n",
       "\n",
       "   EXPECTED_CLOSE_DATE  ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  BUCKET SEX  \\\n",
       "0                 1.18                 91000.0     88223.40       0   M   \n",
       "1                 1.74                 35000.0     33714.82       0   M   \n",
       "2                 1.35                 52500.0     52500.00       0   F   \n",
       "3                 0.10                103000.0     99054.45       0   M   \n",
       "4                 0.82                 94250.0     89450.17       0   M   \n",
       "\n",
       "   CUSTOMER_OPEN_DATE  BIRTH_DATE  PROFESSION    CAR_TYPE  \n",
       "0                3.84       33.45    EMPLOYEE         KIA  \n",
       "1                3.75       34.05    EMPLOYEE       CARRY  \n",
       "2                3.67       34.18   HOUSEWIFE   CHEVROLET  \n",
       "3                3.86       40.68  Shop Owner  MITSUBISHI  \n",
       "4                3.82       42.63  Shop Owner        SEAT  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implement the following 2 methods to automate the Risk-based segmentation process:\n",
    "* You can implement more methods if you think it is necessary.\n",
    "* In computer science, when we are dividing the code it is important to think which code does what. For example, __data cleanning__ and __data preparation__, is it done by the Risk Based Segmentation Class or the class assumes that the data is clean and ready for modelling (all variables are numeric, and dummies are already provided)?\n",
    "* Use: the input dataset should already be clean and ready for the trainning of a Logistic Regression with a binary target 0 and 1 class. \n",
    "* Scope: data cleanning and data preparation is out of the scope of the Class, but notice that .missing_not_at_random() requires the data to have missing values.\n",
    "\n",
    "## 1) Implement a method .missing_not_at_random() \n",
    "To identify different potential segments sharing data (based on sharing missing values) - Expected result is a print:\n",
    "Missing Not At Random Repport (MNAR) -  PROFESSION, SEX and BIRTH_DATE variables seem Missing Not at Random, there for we recommend:\n",
    "\n",
    "&emsp;  Thin File Segment Variables (all others variables free of MNAR issue): REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, \n",
    "OUTSTANDING, CUSTOMER_OPEN_DATE, CAR_TYPE\n",
    "\n",
    "&emsp; Full File Segment Variables: REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, OUTSTANDING, SEX, CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the mnra_columns attribute before running the method called missing_not_at_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Must run the missing_not_at_random method to update this attribute'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.mnra_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    def missing_not_at_random(self, corr_threshold=0.9):\n",
    "        \"\"\"\n",
    "        This method is checks for the correlation between the missing values in all the columns, pair by\n",
    "        pair in order, in order to see if the correlation is higher than threshold to be considered missing\n",
    "        not at random.\n",
    "        -------\n",
    "        corr_threshold: This variable is the threshold that will be used as a cut off to decide if the\n",
    "        correlation between the missing values between a pair of columns is high enough to be considered missing\n",
    "        not at random.\n",
    "        \"\"\"\n",
    "\n",
    "        def redundant_pairs(self):\n",
    "            \"\"\"\n",
    "            This function inside the method is used to find pairs of columns that are\n",
    "            are repeated in the correlation matrix used in the method missing_not_at_random.\n",
    "            \"\"\"\n",
    "            pairs_to_drop = set()\n",
    "            cols = self.columns\n",
    "            for i in range(0, self.shape[1]):\n",
    "                for j in range(0, i + 1):\n",
    "                    pairs_to_drop.add((cols[i], cols[j]))\n",
    "            return pairs_to_drop\n",
    "\n",
    "        NaS = self.iloc[:, [i for i, n in enumerate(np.var(self.isna(), axis='rows')) if n > 0]]\n",
    "        labels_to_drop = redundant_pairs(NaS)\n",
    "        NaS_df = NaS.isnull().corr().unstack()\n",
    "        NaS_corr = NaS_df.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "        mnra_list = []\n",
    "\n",
    "        for i in range(len(NaS_corr)):\n",
    "            if (NaS_corr[i] >= corr_threshold):\n",
    "                mnra_list.append(NaS_corr.index[i])\n",
    "            else:\n",
    "                pass\n",
    "        mnra_columns = list(set([item for sublist in mnra_list for item in sublist]))\n",
    "        full_file_segment_variable = self.num_columns + self.cat_columns\n",
    "        thin_file_segment_variable = [x for x in full_file_segment_variable if x not in mnra_columns]\n",
    "\n",
    "        self.mnra_columns = mnra_columns\n",
    "        self.full_file_segment_variable = full_file_segment_variable\n",
    "        self.thin_file_segment_variable = thin_file_segment_variable\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Not At Random Repport - ['PROFESSION', 'BIRTH_DATE', 'SEX'] variables seem Missing Not at Random,there for we recommend:\n",
      "Thin File Segment Variables: ['ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING', 'BUCKET', 'LOAN_OPEN_DATE', 'EXPECTED_CLOSE_DATE', 'CUSTOMER_OPEN_DATE', 'PROGRAM_NAME', 'CAR_TYPE']\n",
      "Full File Segment Variables: ['ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING', 'BUCKET', 'LOAN_OPEN_DATE', 'EXPECTED_CLOSE_DATE', 'CUSTOMER_OPEN_DATE', 'BIRTH_DATE', 'PROGRAM_NAME', 'SEX', 'PROFESSION', 'CAR_TYPE']\n"
     ]
    }
   ],
   "source": [
    "myrdf.missing_not_at_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results in of the attribute following the method being called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROFESSION', 'BIRTH_DATE', 'SEX']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.mnra_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "OUTPUT SAMPLE:\n",
    "\n",
    "__Missing Not At Random Repport__ -  REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID variables seem Missing Not at Random, there for we recommend:\n",
    "\n",
    "&emsp;  Thin File Segment Variables: PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, \n",
    "ORIGINAL_BOOKED_AMOUNT, OUTSTANDING, SEX, \n",
    "CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "&emsp; Full File Segment Variables: REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, \n",
    "OUTSTANDING, SEX, CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\t2) implement a method .find_segment_split(variable)\n",
    "given one variable, implement a method to identify if the variable is a good segmentation splitter and if the variable is a good splitter,   \n",
    "different segments of customers with different level of risk (the one explained in the second video)\n",
    "* Scope: data cleanning and data preparation is out of the scope of the Class, note that .find_segment_split(VARIABLE) assumes the data is already clean free of missing values.\n",
    "* Categorical: for the segmentation process of categorical variable, dummy transformation is not practical, it is recommended that categorical variables come pre-transformed into numerical by replacing the categories by the Probability of belonging to class 1.\n",
    "* The following code only works for a single variable, implement a loop going over each variable of the dataset as a candidate for segmentation.\n",
    "* The following method must implement two segmentation approaches, one for Categorical Nominal (order not relevant - variable must be automatically transformed) and others where order is important.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the amount of missing rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PROGRAM_NAME              0.000000\n",
       " LOAN_OPEN_DATE            0.000000\n",
       " EXPECTED_CLOSE_DATE       0.000000\n",
       " ORIGINAL_BOOKED_AMOUNT    0.000000\n",
       " OUTSTANDING               0.000000\n",
       " BUCKET                    0.000000\n",
       " SEX                       0.505170\n",
       " CUSTOMER_OPEN_DATE        0.000000\n",
       " BIRTH_DATE                0.505731\n",
       " PROFESSION                0.620796\n",
       " CAR_TYPE                  1.295115\n",
       " dtype: float64,\n",
       " (900860, 11))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.isna().sum()/myrdf.count()*100 , myrdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use simple imputing to fill these rows, as this is out of the score of the RiskDataframe class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>88223.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.84</td>\n",
       "      <td>33.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>CARRY</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>33714.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.75</td>\n",
       "      <td>34.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52500.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.67</td>\n",
       "      <td>34.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>99054.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.86</td>\n",
       "      <td>40.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>SEAT</td>\n",
       "      <td>94250.0</td>\n",
       "      <td>89450.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.82</td>\n",
       "      <td>42.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PROGRAM_NAME SEX  PROFESSION    CAR_TYPE  \\\n",
       "0       Auto Loans 50% Down Payment - Employed   M    EMPLOYEE         KIA   \n",
       "1                     Pick Up and Small Trucks   M    EMPLOYEE       CARRY   \n",
       "2       Auto Loans 40% Down Payment - Employed   F   HOUSEWIFE   CHEVROLET   \n",
       "3  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner  MITSUBISHI   \n",
       "4  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner        SEAT   \n",
       "\n",
       "   ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  BUCKET  LOAN_OPEN_DATE  \\\n",
       "0                 91000.0     88223.40     0.0            3.76   \n",
       "1                 35000.0     33714.82     0.0            3.73   \n",
       "2                 52500.0     52500.00     0.0            3.63   \n",
       "3                103000.0     99054.45     0.0            3.77   \n",
       "4                 94250.0     89450.17     0.0            3.77   \n",
       "\n",
       "   EXPECTED_CLOSE_DATE  CUSTOMER_OPEN_DATE  BIRTH_DATE  \n",
       "0                 1.18                3.84       33.45  \n",
       "1                 1.74                3.75       34.05  \n",
       "2                 1.35                3.67       34.18  \n",
       "3                 0.10                3.86       40.68  \n",
       "4                 0.82                3.82       42.63  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "df_cat = pd.DataFrame(cat_imputer.fit_transform(myrdf[myrdf.cat_columns]))\n",
    "df_cat.columns = myrdf.cat_columns\n",
    "df_num = pd.DataFrame(num_imputer.fit_transform(myrdf[myrdf.num_columns]))\n",
    "df_num.columns = myrdf.num_columns\n",
    "\n",
    "\n",
    "df = df_cat\n",
    "df = df.join(df_num)\n",
    "myrdf = rdf.RiskDataframe(df)\n",
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PROGRAM_NAME              0.0\n",
       " SEX                       0.0\n",
       " PROFESSION                0.0\n",
       " CAR_TYPE                  0.0\n",
       " ORIGINAL_BOOKED_AMOUNT    0.0\n",
       " OUTSTANDING               0.0\n",
       " BUCKET                    0.0\n",
       " LOAN_OPEN_DATE            0.0\n",
       " EXPECTED_CLOSE_DATE       0.0\n",
       " CUSTOMER_OPEN_DATE        0.0\n",
       " BIRTH_DATE                0.0\n",
       " dtype: float64,\n",
       " (900860, 11))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.isna().sum()/myrdf.count()*100 , myrdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to binarize the target variable in order improve model performance and simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    743348\n",
       "1.0    100979\n",
       "2.0     35120\n",
       "3.0     11306\n",
       "4.0      4981\n",
       "5.0      2627\n",
       "7.0      1457\n",
       "6.0      1042\n",
       "Name: BUCKET, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf['BUCKET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>BUCKET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>88223.40</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.84</td>\n",
       "      <td>33.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>CARRY</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>33714.82</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.75</td>\n",
       "      <td>34.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52500.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.67</td>\n",
       "      <td>34.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>99054.45</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.86</td>\n",
       "      <td>40.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>SEAT</td>\n",
       "      <td>94250.0</td>\n",
       "      <td>89450.17</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.82</td>\n",
       "      <td>42.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PROGRAM_NAME SEX  PROFESSION    CAR_TYPE  \\\n",
       "0       Auto Loans 50% Down Payment - Employed   M    EMPLOYEE         KIA   \n",
       "1                     Pick Up and Small Trucks   M    EMPLOYEE       CARRY   \n",
       "2       Auto Loans 40% Down Payment - Employed   F   HOUSEWIFE   CHEVROLET   \n",
       "3  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner  MITSUBISHI   \n",
       "4  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner        SEAT   \n",
       "\n",
       "   ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  LOAN_OPEN_DATE  EXPECTED_CLOSE_DATE  \\\n",
       "0                 91000.0     88223.40            3.76                 1.18   \n",
       "1                 35000.0     33714.82            3.73                 1.74   \n",
       "2                 52500.0     52500.00            3.63                 1.35   \n",
       "3                103000.0     99054.45            3.77                 0.10   \n",
       "4                 94250.0     89450.17            3.77                 0.82   \n",
       "\n",
       "   CUSTOMER_OPEN_DATE  BIRTH_DATE  BUCKET  \n",
       "0                3.84       33.45       0  \n",
       "1                3.75       34.05       0  \n",
       "2                3.67       34.18       0  \n",
       "3                3.86       40.68       0  \n",
       "4                3.82       42.63       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'BUCKET'\n",
    "target_series = myrdf[target]\n",
    "myrdf = myrdf.drop(target, axis=1)\n",
    "target_array = np.vectorize(lambda x: 0 if x == 0 else 1)(target_series)\n",
    "target_df = pd.DataFrame(target_array)\n",
    "target_df = target_df.rename(columns={0:'BUCKET'}) \n",
    "\n",
    "\n",
    "myrdf = myrdf.join(target_df)\n",
    "myrdf.num_columns.append(target)\n",
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    743348\n",
       "1    157512\n",
       "Name: BUCKET, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf['BUCKET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>BUCKET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>88223.40</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.84</td>\n",
       "      <td>33.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>M</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>CARRY</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>33714.82</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.75</td>\n",
       "      <td>34.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52500.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.67</td>\n",
       "      <td>34.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>99054.45</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.86</td>\n",
       "      <td>40.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>Shop Owner</td>\n",
       "      <td>SEAT</td>\n",
       "      <td>94250.0</td>\n",
       "      <td>89450.17</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.82</td>\n",
       "      <td>42.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PROGRAM_NAME SEX  PROFESSION    CAR_TYPE  \\\n",
       "0       Auto Loans 50% Down Payment - Employed   M    EMPLOYEE         KIA   \n",
       "1                     Pick Up and Small Trucks   M    EMPLOYEE       CARRY   \n",
       "2       Auto Loans 40% Down Payment - Employed   F   HOUSEWIFE   CHEVROLET   \n",
       "3  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner  MITSUBISHI   \n",
       "4  Auto Loans 30% Down Payment - Self Employed   M  Shop Owner        SEAT   \n",
       "\n",
       "   ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  LOAN_OPEN_DATE  EXPECTED_CLOSE_DATE  \\\n",
       "0                 91000.0     88223.40            3.76                 1.18   \n",
       "1                 35000.0     33714.82            3.73                 1.74   \n",
       "2                 52500.0     52500.00            3.63                 1.35   \n",
       "3                103000.0     99054.45            3.77                 0.10   \n",
       "4                 94250.0     89450.17            3.77                 0.82   \n",
       "\n",
       "   CUSTOMER_OPEN_DATE  BIRTH_DATE  BUCKET  \n",
       "0                3.84       33.45       0  \n",
       "1                3.75       34.05       0  \n",
       "2                3.67       34.18       0  \n",
       "3                3.86       40.68       0  \n",
       "4                3.82       42.63       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Must run the find_segmentation_split method to update this attribute'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.accuracy_fitted_full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    def find_segment_split(self, target='', robust_scaler=''):\n",
    "        \"\"\"\n",
    "        This method finds if the data in each column performs better if it is split in order to segment the data\n",
    "        and have a better model fit. The model used is logistic regression for a binary classification, which does\n",
    "        not accept alphanumeric values, therefore labelencoder is automatically called if the method detects these\n",
    "        data type columns. The required argument for this method is target, since the logistic regression model needs\n",
    "        this. Robust_scaler is an optional argument in order to enhance model performance. Once the baseline model with\n",
    "        the full file without segmentation is calculated, this method continues to find where is the optimal place\n",
    "        for spltting each column by applying a decision tree classifier, and extracting the root node splitting point.\n",
    "        Finally it fits a model on the segmented dataset and compares the results of both models.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Example 1:\n",
    "        ORIGINAL_BOOKED_AMOUNT: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "        Model Developed on ORIGINAL_BOOKED_AMOUNT Seg 1 (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 1 (test sample): 0.269 %\n",
    "        Model Developed on Full Population (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 1 (test sample): 0.269 %\n",
    "        Model Developed on ORIGINAL_BOOKED_AMOUNT Seg 2 (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 2 (test sample): 0.263 %\n",
    "        Model Developed on Full Population (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 2 (test sample): 0.263 %\n",
    "                \n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.cat_columns) > 0:\n",
    "            df_cat = self[self.cat_columns]\n",
    "            for column in range(len(self.cat_columns)):\n",
    "                df_cat[self.cat_columns[column]] = LabelEncoder().fit_transform(df_cat[self.cat_columns[column]])\n",
    "            self.drop(self.cat_columns, inplace=True, axis=1)\n",
    "            for col in df_cat.columns:\n",
    "                self[col] = df_cat[col]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if robust_scaler.upper() == 'YES':\n",
    "            non_target_df = self.drop(target, axis=1)\n",
    "            scaled_features = RobustScaler().fit_transform(non_target_df.values)\n",
    "            scaled_df = pd.DataFrame(scaled_features, index=non_target_df.index, columns=non_target_df.columns)\n",
    "            self.drop(scaled_df.columns, inplace=True, axis=1)\n",
    "            for col in scaled_df.columns:\n",
    "                self[col] = scaled_df[col]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # Baseline model\n",
    "        df_train, df_test = train_test_split(self, test_size=0.2, random_state=42)\n",
    "        try:\n",
    "            self.num_columns.remove(target)\n",
    "        except:\n",
    "            self.cat_columns.remove(target)\n",
    "        X_train = df_train.drop(target, axis=1)\n",
    "        y_train = df_train[target]\n",
    "        X_test = df_test.drop(target, axis=1)\n",
    "        y_test = df_test[target]\n",
    "        method = LogisticRegression(random_state=0, solver='lbfgs', max_iter=100)\n",
    "        fitted_full_model = method.fit(X_train, y_train)\n",
    "        y_pred_proba = fitted_full_model.predict_proba(X_test)[:, 0]\n",
    "        y_pred = fitted_full_model.predict(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        self.GINI_fitted_full_model = abs((2 * roc_auc) - 1)\n",
    "        self.accuracy_fitted_full_model = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Function to decide where to split\n",
    "        all_columns = self.num_columns + self.cat_columns\n",
    "        split_list = []\n",
    "        def splits(column):\n",
    "            x = self.drop(target, axis=1)\n",
    "            y = self[target]\n",
    "            single_x = np.array(x[column]).reshape(-1, 1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(single_x, y, test_size=0.2, random_state=42)\n",
    "            method = DecisionTreeClassifier(random_state=0, max_depth=3)\n",
    "            individual_feature_model = method.fit(X_train, y_train)\n",
    "            y_pred = individual_feature_model.predict(X_test)\n",
    "            split = str(tree.export_text(individual_feature_model))\n",
    "            split = float(split[17:23])\n",
    "            split_list.append(split)\n",
    "            return split_list\n",
    "        np.vectorize(splits, otypes=[list])(all_columns)\n",
    "        self.variable_split = dict(zip(all_columns, split_list))\n",
    "\n",
    "        # Function to decide if good segmentation loop\n",
    "        def segmentation(column, split):\n",
    "            df_train_seg1 = df_train[self[column] > split]\n",
    "            df_train_seg2 = df_train[self[column] <= split]\n",
    "            df_test_seg1 = df_test[self[column] > split]\n",
    "            df_test_seg2 = df_test[self[column] <= split]\n",
    "\n",
    "            X_train_seg1 = df_train_seg1[all_columns]\n",
    "            y_train_seg1 = df_train_seg1[target]\n",
    "            X_test_seg1 = df_test_seg1[all_columns]\n",
    "            y_test_seg1 = df_test_seg1[target]\n",
    "\n",
    "            fitted_model_seg1 = method.fit(X_train_seg1, y_train_seg1)\n",
    "            y_pred_seg1 = fitted_model_seg1.predict_proba(X_test_seg1)[:, 1]\n",
    "            y_pred_seg1_fullmodel = fitted_full_model.predict_proba(X_test_seg1)[:, 1]\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test_seg1, y_pred_seg1)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            GINI_seg1 = round(abs((2 * roc_auc) - 1),3)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test_seg1, y_pred_seg1_fullmodel)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            GINI_seg1_full = round(abs((2 * roc_auc) - 1),3)\n",
    "\n",
    "            X_train_seg2 = df_train_seg2[all_columns]\n",
    "            y_train_seg2 = df_train_seg2[target]\n",
    "            X_test_seg2 = df_test_seg2[all_columns]\n",
    "            y_test_seg2 = df_test_seg2[target]\n",
    "\n",
    "            fitted_model_seg2 = method.fit(X_train_seg2, y_train_seg2)\n",
    "            y_pred_seg2 = fitted_model_seg2.predict_proba(X_test_seg2)[:, 1]\n",
    "            y_pred_seg2_fullmodel = fitted_full_model.predict_proba(X_test_seg2)[:, 1]\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test_seg2, y_pred_seg2)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            GINI_seg2 = round(abs((2 * roc_auc) - 1),3)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test_seg2, y_pred_seg2_fullmodel)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            GINI_seg2_full = round(abs((2 * roc_auc) - 1),3)\n",
    "\n",
    "            if GINI_seg1 > GINI_seg1_full and GINI_seg2 > GINI_seg2_full:\n",
    "                print(f'{column}: Good for segmentation.')\n",
    "                print(f'Segment1: {column} > {split} [GINI Full Model: {GINI_seg1_full}% / GINI Segmented Model: {GINI_seg1}')\n",
    "                print(f'Segment2: {column} > {split} [GINI Full Model: {GINI_seg2_full}% / GINI Segmented Model: {GINI_seg2}')\n",
    "            else:\n",
    "                print(f'{column}: Not good for segmentation. Afer analysis, we did not find a good split using this variable.')\n",
    "\n",
    "            print(f\"Model Developed on {column} Seg 1 (train sample) applied on {column} Seg 1 (test sample):\",\n",
    "                  GINI_seg1,'%')\n",
    "            print(f\"Model Developed on Full Population (train sample) applied on {column} Seg 1 (test sample):\",\n",
    "                  GINI_seg1_full,'%')\n",
    "            print(f\"Model Developed on {column} Seg 2 (train sample) applied on {column} Seg 2 (test sample):\",\n",
    "                  GINI_seg2,'%')\n",
    "            print(f\"Model Developed on Full Population (train sample) applied on {column} Seg 2 (test sample):\",\n",
    "                  GINI_seg2_full,'%')\n",
    "        np.vectorize(segmentation, otypes=[list])(all_columns, split_list)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL_BOOKED_AMOUNT: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on ORIGINAL_BOOKED_AMOUNT Seg 1 (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 1 (test sample): 0.238 %\n",
      "Model Developed on Full Population (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 1 (test sample): 0.238 %\n",
      "Model Developed on ORIGINAL_BOOKED_AMOUNT Seg 2 (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 2 (test sample): 0.265 %\n",
      "Model Developed on Full Population (train sample) applied on ORIGINAL_BOOKED_AMOUNT Seg 2 (test sample): 0.265 %\n",
      "OUTSTANDING: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on OUTSTANDING Seg 1 (train sample) applied on OUTSTANDING Seg 1 (test sample): 0.256 %\n",
      "Model Developed on Full Population (train sample) applied on OUTSTANDING Seg 1 (test sample): 0.256 %\n",
      "Model Developed on OUTSTANDING Seg 2 (train sample) applied on OUTSTANDING Seg 2 (test sample): 0.256 %\n",
      "Model Developed on Full Population (train sample) applied on OUTSTANDING Seg 2 (test sample): 0.256 %\n",
      "LOAN_OPEN_DATE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on LOAN_OPEN_DATE Seg 1 (train sample) applied on LOAN_OPEN_DATE Seg 1 (test sample): 0.22 %\n",
      "Model Developed on Full Population (train sample) applied on LOAN_OPEN_DATE Seg 1 (test sample): 0.22 %\n",
      "Model Developed on LOAN_OPEN_DATE Seg 2 (train sample) applied on LOAN_OPEN_DATE Seg 2 (test sample): 0.213 %\n",
      "Model Developed on Full Population (train sample) applied on LOAN_OPEN_DATE Seg 2 (test sample): 0.213 %\n",
      "EXPECTED_CLOSE_DATE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on EXPECTED_CLOSE_DATE Seg 1 (train sample) applied on EXPECTED_CLOSE_DATE Seg 1 (test sample): 0.249 %\n",
      "Model Developed on Full Population (train sample) applied on EXPECTED_CLOSE_DATE Seg 1 (test sample): 0.249 %\n",
      "Model Developed on EXPECTED_CLOSE_DATE Seg 2 (train sample) applied on EXPECTED_CLOSE_DATE Seg 2 (test sample): 0.255 %\n",
      "Model Developed on Full Population (train sample) applied on EXPECTED_CLOSE_DATE Seg 2 (test sample): 0.255 %\n",
      "CUSTOMER_OPEN_DATE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on CUSTOMER_OPEN_DATE Seg 1 (train sample) applied on CUSTOMER_OPEN_DATE Seg 1 (test sample): 0.254 %\n",
      "Model Developed on Full Population (train sample) applied on CUSTOMER_OPEN_DATE Seg 1 (test sample): 0.254 %\n",
      "Model Developed on CUSTOMER_OPEN_DATE Seg 2 (train sample) applied on CUSTOMER_OPEN_DATE Seg 2 (test sample): 0.203 %\n",
      "Model Developed on Full Population (train sample) applied on CUSTOMER_OPEN_DATE Seg 2 (test sample): 0.203 %\n",
      "BIRTH_DATE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on BIRTH_DATE Seg 1 (train sample) applied on BIRTH_DATE Seg 1 (test sample): 0.278 %\n",
      "Model Developed on Full Population (train sample) applied on BIRTH_DATE Seg 1 (test sample): 0.278 %\n",
      "Model Developed on BIRTH_DATE Seg 2 (train sample) applied on BIRTH_DATE Seg 2 (test sample): 0.223 %\n",
      "Model Developed on Full Population (train sample) applied on BIRTH_DATE Seg 2 (test sample): 0.223 %\n",
      "PROGRAM_NAME: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on PROGRAM_NAME Seg 1 (train sample) applied on PROGRAM_NAME Seg 1 (test sample): 0.291 %\n",
      "Model Developed on Full Population (train sample) applied on PROGRAM_NAME Seg 1 (test sample): 0.291 %\n",
      "Model Developed on PROGRAM_NAME Seg 2 (train sample) applied on PROGRAM_NAME Seg 2 (test sample): 0.196 %\n",
      "Model Developed on Full Population (train sample) applied on PROGRAM_NAME Seg 2 (test sample): 0.196 %\n",
      "SEX: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on SEX Seg 1 (train sample) applied on SEX Seg 1 (test sample): 0.248 %\n",
      "Model Developed on Full Population (train sample) applied on SEX Seg 1 (test sample): 0.248 %\n",
      "Model Developed on SEX Seg 2 (train sample) applied on SEX Seg 2 (test sample): 0.265 %\n",
      "Model Developed on Full Population (train sample) applied on SEX Seg 2 (test sample): 0.265 %\n",
      "PROFESSION: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on PROFESSION Seg 1 (train sample) applied on PROFESSION Seg 1 (test sample): 0.268 %\n",
      "Model Developed on Full Population (train sample) applied on PROFESSION Seg 1 (test sample): 0.268 %\n",
      "Model Developed on PROFESSION Seg 2 (train sample) applied on PROFESSION Seg 2 (test sample): 0.253 %\n",
      "Model Developed on Full Population (train sample) applied on PROFESSION Seg 2 (test sample): 0.253 %\n",
      "CAR_TYPE: Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
      "Model Developed on CAR_TYPE Seg 1 (train sample) applied on CAR_TYPE Seg 1 (test sample): 0.255 %\n",
      "Model Developed on Full Population (train sample) applied on CAR_TYPE Seg 1 (test sample): 0.255 %\n",
      "Model Developed on CAR_TYPE Seg 2 (train sample) applied on CAR_TYPE Seg 2 (test sample): 0.246 %\n",
      "Model Developed on Full Population (train sample) applied on CAR_TYPE Seg 2 (test sample): 0.246 %\n"
     ]
    }
   ],
   "source": [
    "myrdf.find_segment_split(target='BUCKET', robust_scaler='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>0.712837</td>\n",
       "      <td>-0.121547</td>\n",
       "      <td>-0.039735</td>\n",
       "      <td>-0.158654</td>\n",
       "      <td>-0.428502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.826531</td>\n",
       "      <td>-0.260049</td>\n",
       "      <td>-0.138122</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>-0.201923</td>\n",
       "      <td>-0.389547</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.469388</td>\n",
       "      <td>0.075235</td>\n",
       "      <td>-0.193370</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>-0.240385</td>\n",
       "      <td>-0.381107</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.906153</td>\n",
       "      <td>-0.116022</td>\n",
       "      <td>-0.754967</td>\n",
       "      <td>-0.149038</td>\n",
       "      <td>0.040902</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.382653</td>\n",
       "      <td>0.734733</td>\n",
       "      <td>-0.116022</td>\n",
       "      <td>-0.278146</td>\n",
       "      <td>-0.168269</td>\n",
       "      <td>0.167505</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BUCKET  ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  LOAN_OPEN_DATE  \\\n",
       "0       0                0.316327     0.712837       -0.121547   \n",
       "1       0               -0.826531    -0.260049       -0.138122   \n",
       "2       0               -0.469388     0.075235       -0.193370   \n",
       "3       0                0.561224     0.906153       -0.116022   \n",
       "4       0                0.382653     0.734733       -0.116022   \n",
       "\n",
       "   EXPECTED_CLOSE_DATE  CUSTOMER_OPEN_DATE  BIRTH_DATE  PROGRAM_NAME  SEX  \\\n",
       "0            -0.039735           -0.158654   -0.428502      0.000000  0.0   \n",
       "1             0.331126           -0.201923   -0.389547      2.500000  0.0   \n",
       "2             0.072848           -0.240385   -0.381107     -0.333333 -1.0   \n",
       "3            -0.754967           -0.149038    0.040902     -0.833333  0.0   \n",
       "4            -0.278146           -0.168269    0.167505     -0.833333  0.0   \n",
       "\n",
       "   PROFESSION  CAR_TYPE  \n",
       "0    0.000000  0.227273  \n",
       "1    0.000000 -0.909091  \n",
       "2    0.181818 -0.772727  \n",
       "3    2.363636  0.636364  \n",
       "4    2.363636  1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8240681126923163"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.accuracy_fitted_full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "## Mandatory (part 1 - p1) -  Implement the following: (5 out of 10 points)\n",
    "\n",
    "- __Project Name__: pick a name for your project (if it is taken at https://pypi.org/ please create small variations), I recommend you get inspiration by the following Pockemon names: some_pockemon_examples.zip\n",
    "\n",
    "- __Project Managment (Github)__: Work in group using Github, invite professor manoelgad@gmail.com as a collaborator to your project from the very beggining.\n",
    "\n",
    "- __Implementation__: Discuss in group and decide the implementation you need to do for each method (missing_not_at_random and find_segment_split), then do the implementation of missing_not_at_random and find_segment_split. Your implementation should work in any dataset (make the necessary assumption and inform the user if the assumption are not followed, for example: inform the dataset must be clean and types must be informed in case they are not). \n",
    "\n",
    "- __Video__: Create a video from 5 to 15 minutes explainning the whole library (including p1 and p2) and showing examples of how to use it. The video will not be assessed own its own and won't be assessed by colleagues. The video can be very simple, just the notebook/python class and someone explainning things. Upload the video to Youtube and include a link to the video in the website if your group decide to pick Publishing below.    \n",
    "\n",
    "\n",
    "## Improvements (part 2 - p2) -  Implement 2 of the following list of tasks:  (5 out of 10 points)\n",
    "\n",
    "- __Improving__: Make improvements to the code -  Reliable/Robust: Create a train-test split, train all models in train and test all models always in test; Robust: Research and apply a statistical test to decide when the accuracy diffrence in statiscally relevant. Small functions/methods: Break your implementation into small functions/methods; Fast: Optimize your code, use vectorization when possible. Use stratified random sampling to reduce dataset sizes and therefore speed up the segmentation process. Implement segmentation split using Tree algorithm.\n",
    "\n",
    "- __Publishing__: Publish your code in GitHub -  Work in group using Github, invite professor manoelgad@gmail.com as a collaborator to your project from the very beggining. Create a python package and distribute your package using https://pypi.org/, by the end of the project one must be able to pip install your project and use it.\n",
    "References: https://www.youtube.com/watch?v=GIF3LaRqgXo; and  https://github.com/judy2k/publishing_python_packages_talk\n",
    "\n",
    "- __Testing__: Implement a Test class using unittest with an \"comprehensive\" set of tests using a series of datasets of your choice. Have a look at this: https://ains.co/blog/things-which-arent-magic-flask-part-1.html and https://www.youtube.com/watch?v=1Lfv5tUGsn8\n",
    "\n",
    "- __Documentation__: create a documentation for your project and publish it at GitHub project (readme) and also a pythonanywhere.com website (simple HTML). The documentation must contain an about, a how to and also examples of how to use with one or more datasets. All used datasets should be provided within the project (make sure you don't share huge datasets, make it small before sharing your code).\n",
    "\n",
    "- __Logging & Repporting__: Log all intermediate results and final results into a Sqlite database using SQLAlchemy, then produce the final result repport in HTML format using Bokeh.\n",
    "\n",
    "\n",
    "# Evaluation criteria\n",
    "\n",
    "All team members have the choice of focusing, by choising 1 or 2 of the tasks of part 2.\n",
    "*   If 1 task of part 2 is choosen, grade will be: p1\\*0.5 + p2x\\*0.4 + (p2y\\*0.1) (p2x is the grade in the choosen task and p2y the other) \n",
    "*   If 2 tasks of part 2 are choosen, grade will be: p1\\*0.5 + (p2x\\*0.25 + p2y\\*0.25)\n",
    "* If your group only implement 1 extra part, all members will be assessed using: p1\\*0.5 + p2x\\*0.4 + (p2y\\*0.1)\n",
    "* If your group implements more then 2 parts, please indicate the ones you want to be assessed upon.\n",
    "\n",
    "\n",
    "What professor will look at when assessing the project:\n",
    "*\tProblem structuring - How did you structure the problem and the project?\n",
    "*\tWhat assumptions did you make? (Please mention them in the video)\n",
    "*\tHow did you narrow the scope? (Please mention them in the video)\n",
    "*\tTechnical Skills: How reliable (does it use your own class? does is it apply data quality controls?)), readable and flexible (can you apply your code to a new dataset?) was the code that you developed?\n",
    "* Analytical Skills: How logically sound, complete and meaningful was the approach (machine learning, statistics, analytics, visualizationâ€¦) that you applied?\n",
    "*\tUsefulness:\tHow useful would the results of your work for new datasets?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "You are allowed to use __Python only__ and any Python Library inside your Jupyter Notebook or inside your Class, always give preference to Pandas and Scikit Learn whenever you can.\n",
    "\n",
    "\n",
    "\n",
    "# Deliverables\n",
    "*\tA zip file with all code and datasets used for the projet.\n",
    "\n",
    "\n",
    "# Data description\n",
    "We will provide you with historical data of car loans. The data contains monthly status for each loan for 3 years. In addition to some demographic information\n",
    "\n",
    "# Notes:\n",
    "*\tThis data is Loan level NOT Customer level, meaning that one customer can take more than one loan\n",
    "*\tThe data is monthly starting from 2016-01-01 to 2019-09-01 so if the loan already started before Jan2016 you will find partial history for it.\n",
    "*\tWe have multiple programs under the car loans product\n",
    "*\tMake sure you understand the difference between Buckets\n",
    "\n",
    "# Research:\n",
    "In order to implement the methods missing_not_at_random and find_segment_split, you are allowed to search for whichever information you need in the internet including but not limited to:\n",
    "*\tCode syntax\n",
    "*\tBusiness term (However you can ask me)\n",
    "\n",
    "Start by looking into these 3 videos:\n",
    "*\tWhat is Risk-based segmentation? https://www.youtube.com/watch?v=2ZpLgUcucfQ \n",
    "*   This is a generic video on Segmentation, it is a good reference, but careful not all needs to be implemented and not all mentioned here is relevant for this project: https://www.youtube.com/watch?v=PLsUfDDytaE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX: \n",
    "\n",
    "## Simple example of Risk Based Segmentation\n",
    "\n",
    "*   Video explainning the code below: https://www.youtube.com/watch?v=kWtnlpGwh_o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe#pd.read_csv(\"AUTO_LOANS_DATA.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argument_dict = {'REPORTING_DATE':'datetime64[ns]','LOAN_OPEN_DATE':'datetime64[ns]',\n",
    "                 'EXPECTED_CLOSE_DATE':'datetime64[ns]','CUSTOMER_OPEN_DATE':'datetime64[ns]',\n",
    "                 'BIRTH_DATE':'datetime64[ns]','PROGRAM_NAME':'category','BUCKET':'category','SEX':'category',\n",
    "                'PROFESSION':'category','CAR_TYPE':'category'}\n",
    "myrdf.SetAttributes(argument_dict)\n",
    "myrdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sample trick to speed up the process..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = dataframe\n",
    "df_random_sample, _ = train_test_split(dataframe, test_size=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirty variable selection, feature transformation and data cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_columns(df, data_types, to_ignore = list(), ignore_target = False):\n",
    "    columns = df.select_dtypes(include=data_types).columns\n",
    "    if ignore_target:\n",
    "        columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "    return list(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'BINARIZED_TARGET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_numeric_variables = get_specific_columns(df, [\"float64\", \"int64\"], [target], ignore_target = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression - Full Model - all variables\n",
    "You sould use LogisticRegression in the modeling part to avoid any overfitting issues, and also split your data into train and test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "splitter = train_test_split\n",
    "\"-----------------------\"\n",
    "\n",
    "df_train, df_test = splitter(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[all_numeric_variables]\n",
    "y_train = df_train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[all_numeric_variables]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "method = LogisticRegression(random_state=0)\n",
    "fitted_full_model = method.fit(X_train, y_train)\n",
    "y_pred = fitted_full_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINI vs Accuracy - use GINI for this analysis!\n",
    "\n",
    "GINI as well as accuracy is a 0 to 1 measure, 0 being very bad prediction and 1 being perfect separation.\n",
    "For this project __you should use GINI__ as it looks the model in all predictions (all range of probabilities), accuracy gets the probability and using a cut-off and transform the probability into predicted class 0 for probabilities below 50% and predicted class 1 for above or equal to 50%. So using accuracy makes our analysis for segmentation very short sighted as the result of the analysis could change if one changes the cut-off to let say 40%, for this reason we will use the GINI coeficient which is independent of the cut-off having a better overview of the whole model predictions.\n",
    "\n",
    "GINI is a simple calculation resulting from AUC. You will not find directly the Gini Coefficient as an attribute for the LogisticRegressor Class, but you can use the 2*AUC-1 formula to calculate it. \n",
    "\n",
    "If you want more details about GINI have a look into this video:\n",
    "https://www.youtube.com/watch?v=MiBUBVUC8kE\n",
    "\n",
    "\n",
    "Make sure you use .predict_proba (to predict probability) and then get the first column using [:,1] to get only the probability of being 1, instead of .predict which gives the 0 or 1 class. This proba is  what you need to pass as predictions_list below, to finally obtain the GINI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probadbility = fitted_full_model.predict_proba(X_test)[:,1]\n",
    "#y_test is your actual 0 and 1 class and y_pred_probadbility is the predicted probability of belonging to class 1.\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probadbility)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "GINI = (2 * roc_auc) - 1\n",
    "print(GINI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Model 1 - Gender M and F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_seg1 = df_train[df['SEX'] == \"M\"]\n",
    "df_train_seg2 = df_train[df['SEX'] != \"M\"]\n",
    "df_test_seg1 = df_test[df['SEX'] == \"M\"]\n",
    "df_test_seg2 = df_test[df['SEX'] != \"M\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model vs Seg 1 on Seg 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seg1 = df_train_seg1[all_numeric_variables]\n",
    "y_train_seg1 = df_train_seg1[target]\n",
    "X_test_seg1 = df_test_seg1[all_numeric_variables]\n",
    "y_test_seg1 = df_test_seg1[target]\n",
    "fitted_model_seg1 = method.fit(X_train_seg1, y_train_seg1)\n",
    "\n",
    "def GINI(y_test, y_pred_probadbility):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probadbility)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    GINI = (2 * roc_auc) - 1\n",
    "    return(GINI)\n",
    "\n",
    "y_pred_seg1_proba = fitted_model_seg1.predict_proba(X_test_seg1)[:,1]\n",
    "y_pred_seg1_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg1)[:,1]\n",
    "\n",
    "print(\"Segment1: SEX in ('M') [GINI Full Model: {:.4f}% / GINI Segmented Model: {:.4f}%]\".format(\n",
    "    GINI(y_test_seg1, y_pred_seg1_proba)*100,\n",
    "    GINI(y_test_seg1, y_pred_seg1_fullmodel_proba)*100\n",
    ")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model vs Seg 2 on Seg 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seg2 = df_train_seg2[all_numeric_variables]\n",
    "y_train_seg2 = df_train_seg2[target]\n",
    "X_test_seg2 = df_test_seg2[all_numeric_variables]\n",
    "y_test_seg2 = df_test_seg2[target]\n",
    "fitted_model_seg2 = method.fit(X_train_seg2, y_train_seg2)\n",
    "\n",
    "y_pred_seg2_proba = fitted_model_seg2.predict_proba(X_test_seg2)[:,1]\n",
    "y_pred_seg2_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg2)[:,1]\n",
    "\n",
    "print(\"Segment1: SEX in ('F') [GINI Full Model: {:.4f}% / GINI Segmented Model: {:.4f}%]\".format(\n",
    "    GINI(y_test_seg2, y_pred_seg2_proba)*100,\n",
    "    GINI(y_test_seg2, y_pred_seg2_fullmodel_proba)*100\n",
    "))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Summary Repport\n",
    "\n",
    "&emsp;\n",
    "BUCKET is the target variable and was not analyzed separetly.\n",
    "\n",
    "__Missing Not At Random Repport__ -  REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID variables seem Missing Not at Random, there for we recommend:\n",
    "\n",
    "&emsp;  Thin File Segment Variables: PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, \n",
    "ORIGINAL_BOOKED_AMOUNT, OUTSTANDING, SEX, \n",
    "CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "&emsp; Full File Segment Variables: REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, \n",
    "OUTSTANDING, SEX, CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "__Variable by Variable Risk Based Segmentation Analysis__:\n",
    "\n",
    "&emsp; REPORTING_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; ACCOUNT_NUMBER Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CUSTOMER_ID Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; PROGRAM_NAME Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; LOAN_OPEN_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; EXPECTED_CLOSE_DATE Good for segmentation.  \n",
    "\n",
    "&emsp; &emsp; Segment1: EXPECTED_CLOSE_DATE < '22/07/2021'  [GINI Full Model: 32.1234% / GINI Segmented Model: 33.4342%]\n",
    "\n",
    "&emsp; &emsp;  Segment2: EXPECTED_CLOSE_DATE >= '22/07/2021' [GINI Full Model: 63.7523% / GINI Segmented Model: 68.8342%]\n",
    "\n",
    "&emsp; ORIGINAL_BOOKED_AMOUNT Good for segmentation.  \n",
    "\n",
    "&emsp; &emsp; Segment1: ORIGINAL_BOOKED_AMOUNT < 90000 [GINI Full Model: 32.3243% / GINI Segmented Model: 33.9833%]\n",
    "\n",
    "&emsp; &emsp; Segment2: ORIGINAL_BOOKED_AMOUNT >= 90000 [GINI Full Model: 63.3449% / GINI Segmented Model: 68.9438%]\n",
    "\n",
    "&emsp; OUTSTANDING Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; SEX Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CUSTOMER_OPEN_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CUSTOMER_OPEN_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; BIRTH_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; PROFESSION Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CAR_TYPE Good for segmentation.  \n",
    "\n",
    "&emsp; &emsp; Segment1: CAR_TYPE in (BMW', 'BYD', 'CARRY', 'Changan', 'CHEVROLET', 'Gelory', 'GELY', 'HYUNDAI') [GINI Full Model: 35.3492% / GINI Segmented Model: 37.3943%]\n",
    "\n",
    "&emsp; &emsp; Segment2: CAR_TYPE in ('Jack', 'KIA', 'MERCEDES', 'MITSUBISHI', 'NISSAN', 'RENAULT', 'SEAT', 'SKODA', 'SUZUKI') [GINI Full Model: 42.4324% / GINI Segmented Model: 49.4393%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
